\documentclass[utf8x,hyperref={pdfpagelabels=false}]{beamer}

\usepackage[utf8x]{inputenc}
\usepackage[OT1]{fontenc}
\usepackage{amsmath,graphicx}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{tikz}

\usetikzlibrary{arrows}
\usetikzlibrary{calc}

\usetheme{Malmoe}  % Now it's a beamer presentation with the lisa theme!        
\usecolortheme{beaver}
\setbeamertemplate{footline}[page number]
\setbeamertemplate{navigation symbols}{}

\title{Recurrent Neural Networks in Theano}

\author{%
Phil\'{e}mon Brakel
}
\date{August 11, 2015}

\definecolor{termblue}{RGB}{51, 51, 179}
\newcommand{\term}[1]{\textcolor{termblue}{#1}}

\begin{document}

\begin{frame}[plain]
 \titlepage
\end{frame}

\setcounter{page}{1}

\section{Recap RNNs}

\begin{frame}
    \frametitle{Recurrent Neural Networks}
    \begin{itemize}
        \item Can process sequences of variable length
        \item Used to process speech, language, music,\dots
        \item Non-linear, distributed representations, no Markov assumptions
        \item \emph{BUT} training can be challenging
        \item Learning long-term dependencies is difficult
        \item Computations are not as easy to \emph{parallelize}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Standard Architecture}
\begin{figure}[t]
\centering
\begin{tikzpicture}[->,thick]
\scriptsize
\tikzstyle{main}=[circle, minimum size = 7mm, thick, draw =black!80, node distance = 12mm]
\foreach \name in {1,...,6}
    \node[main, fill = white!100] (y\name) at (\name,1.5) {$\mathbf{y}_\name$};
\foreach \name in {1,...,6}
    \node[main, fill = white!100] (h\name) at (\name,0) {$\mathbf{h}_\name$};
\foreach \name in {1,...,6}
    \node[main, fill = white!100] (x\name) at (\name,-1.5) {$\mathbf{x}_\name$};
\foreach \h in {1,...,6}
       {
        \path (x\h) edge (h\h);
        \path (h\h) edge (y\h);
       }
\foreach \current/\next in {1/2,2/3,3/4,4/5,5/6} 
       {
        \path (h\current) edge (h\next);
       }
    %\node[main] (G-\name) at (\x,0) {$\name$};
\end{tikzpicture}
\caption{A simple Recurrent Neural Network}
\label{fig:birnn}
\end{figure}
\end{frame}
\begin{frame}
    \begin{align*}
        h_t &= q(W_{xh}x_t + W_{hh}h_{t-1} + b_h)\\
        y_t &= r(W_{hy}h_{t} + b_y)
    \end{align*}
\end{frame}

\begin{frame}
    \frametitle{Update Equations}
    \begin{align*}
        i_t &= \tanh(W_{xi}x_t + W_{hi}h_{t-1} + b_i)\\
        j_t &= \sigma(W_{xj}x_t + W_{hj}h_{t-1} + b_j)\\
        f_t &= \sigma(W_{xf}x_t + W_{hf}h_{t-1} + b_f)\\
        o_t &= \sigma(W_{xo}x_t + W_{ho}h_{t-1} + b_o)\\
        c_t &= f_t \otimes c_{t-1} + i_t \otimes j_t\\
        h_t &= \tanh(c_t) \otimes o_t
    \end{align*}
\end{frame}

\section{Long Short-Term Memory}
\begin{frame}
    \frametitle{Long Short-Term Memory (LSTM)}
    Learn long term dependencies by asserting more control over what goes in and out of \emph{memory cells}.
\end{frame}

\begin{frame}
\frametitle{Long Short-Term Memory}
\begin{figure}[t]
\centering
\includegraphics{lstmjozefowicz15}
\caption{LSTM\footnote{Taken from Jozefowicz et al. (2015)}}
\end{figure}
\end{frame}

\begin{frame}
\begin{figure}[t]
\centering
\begin{tikzpicture}[->,thick]
\scriptsize
\tikzstyle{main}=[circle, minimum size = 7mm, thick, draw =black!80, node distance = 12mm]
\foreach \name in {1,...,6}
    \node[main, fill = white!100] (l\name) at (\name,2.3) {$\mathbf{h}^2_\name$};
\foreach \name in {1,...,6}
    \node[main, fill = white!100] (k\name) at (\name,3.1) {$\hat{\mathbf{h}}^2_\name$};
\foreach \name in {1,...,6}
    \node[main, fill = white!100] (i\name) at (\name,.8) {$\hat{\mathbf{h}}^1_\name$};
\foreach \name in {1,...,6}
    \node[main, fill = white!100] (h\name) at (\name,0) {$\mathbf{h}^1_\name$};
\foreach \name in {1,...,6}
    \node[main, fill = white!100] (x\name) at (\name,-1.5) {$\mathbf{x}_\name$};
\foreach \h in {1,...,6}
       {
        \path (x\h) edge [bend right] (i\h);
        \path (x\h) edge (h\h);
        \path (i\h) edge [bend left] (k\h);
        \path (h\h) edge [bend right] (l\h);
        \path (h\h) edge [bend left] (k\h);
        \path (i\h) edge (l\h);
       }
\foreach \current/\next in {1/2,2/3,3/4,4/5,5/6} 
       {
        \path (i\next) edge (i\current);
        \path (h\current) edge (h\next);
        \path (k\next) edge (k\current);
        \path (l\current) edge (l\next);
       }
    %\node[main] (G-\name) at (\x,0) {$\name$};
\end{tikzpicture}
\caption{Two Bidirectional Recurrent Neural Networks stacked on top of each
other.}
\label{fig:birnn}
\end{figure}
\end{frame}

\begin{frame}
    \frametitle{Parallelizing RNN computations}
    Apply RNNs to \emph{batches} of sequences\\
    \begin{block}{Example}
        Present the data as a 3D tensor of $(T \times B \times F)$.
        Each dynamic update will now be a matrix multiplication.
    \end{block}

\end{frame}

\begin{frame}
    \frametitle{Parallelizing RNN computations}
\centering
\resizebox{8cm}{5cm}{
\begin{tikzpicture}
\tikzset{every cell/.style={draw=white}}
\tikzset{every cell 1/.style={fill=gray}}

   \foreach \row [count=\y] in {%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0}}
     \foreach \cell [count=\x] in \row  {
        \path [every cell/.try, every cell \cell/.try]
        (\x,-\y) rectangle ++(1,1);
       }
\end{tikzpicture}
}
\end{frame}

\begin{frame}
\centering
\resizebox{4cm}{2.5cm}{
\begin{tikzpicture}
\tikzset{every cell/.style={draw=black}}
\tikzset{every cell 1/.style={fill=gray}}

   \foreach \row [count=\y] in {%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0}}
     \foreach \cell [count=\x] in \row  {
        \path [every cell/.try, every cell \cell/.try]
        (\x,-\y) rectangle ++(1,1);
       }
\end{tikzpicture}
}
\resizebox{4cm}{2.5cm}{
\begin{tikzpicture}
\tikzset{every cell/.style={draw=black}}
\tikzset{every cell 1/.style={draw=black}}

   \foreach \row [count=\y] in {%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0}}
     \foreach \cell [count=\x] in \row  {
        \path [every cell/.try, every cell \cell/.try]
        (\x,-\y) rectangle ++(1,1) node[below left] {$\cell$};
       }
\end{tikzpicture}
}
\end{frame}

\begin{frame}
\centering
\resizebox{8cm}{5cm}{
\begin{tikzpicture}
\tikzset{every cell/.style={draw=black}}
\tikzset{every cell 1/.style={fill=gray}}

   \foreach \row [count=\y] in {%
     {1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0},%
     {1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1},%
     {1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0},%
     {1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0},%
     {1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0},%
     {1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0}}
     \foreach \cell [count=\x] in \row  {
        \path [every cell/.try, every cell \cell/.try]
        (\x,-\y) rectangle ++(1,1);
       }
\end{tikzpicture}
}
\end{frame}

\section{RNNs with scan}




\end{document}
